# Domande e Risposte - Calcolatori Elettronici A.A. 2024-2025

## Indice
- [Domande e Risposte - Calcolatori Elettronici A.A. 2024-2025](#domande-e-risposte---calcolatori-elettronici-aa-2024-2025)
	- [Indice](#indice)
	- [1. Architettura di Base e Memoria](#1-architettura-di-base-e-memoria)
		- [Domanda 1.1 (answered)](#domanda-11-answered)
		- [Domanda 1.2 (answered)](#domanda-12-answered)
		- [Domanda 1.3 (answered)](#domanda-13-answered)
		- [Domanda 1.4 (answered)](#domanda-14-answered)
	- [2. Memoria Cache](#2-memoria-cache)
		- [Domanda 2.1 (answered)](#domanda-21-answered)
		- [Domanda 2.2](#domanda-22)
		- [Domanda 2.3](#domanda-23)
		- [Domanda 2.4](#domanda-24)
		- [Domanda 2.5](#domanda-25)
		- [Domanda 2.6 (answered)](#domanda-26-answered)
		- [Domanda 2.7](#domanda-27)
		- [Domanda 2.8](#domanda-28)
		- [Domanda 2.9](#domanda-29)
	- [3. Interruzioni](#3-interruzioni)
		- [Domanda 3.1 (answered)](#domanda-31-answered)
		- [Domanda 3.2 (answered)](#domanda-32-answered)
		- [Domanda 3.3 (answered)](#domanda-33-answered)
		- [Domanda 3.4](#domanda-34)
		- [Domanda 3.5 (answered)](#domanda-35-answered)
		- [Domanda 3.6](#domanda-36)
		- [Domanda 3.7](#domanda-37)
		- [Domanda 3.8](#domanda-38)
		- [Domanda 3.9](#domanda-39)
		- [Domanda 3.10](#domanda-310)
		- [Domanda 3.11](#domanda-311)
		- [Domanda 3.12](#domanda-312)
		- [Domanda 3.13](#domanda-313)
		- [Domanda 3.14](#domanda-314)
		- [Domanda 3.15](#domanda-315)
		- [Domanda 3.16](#domanda-316)
		- [Domanda 3.17](#domanda-317)
		- [Domanda 3.18](#domanda-318)
		- [Domanda 3.19](#domanda-319)
	- [4. Eccezioni](#4-eccezioni)
		- [Domanda 4.1 (answered)](#domanda-41-answered)
		- [Domanda 4.2](#domanda-42)
		- [Domanda 4.3](#domanda-43)
		- [Domanda 4.4](#domanda-44)
		- [Domanda 4.5](#domanda-45)
		- [Domanda 4.6](#domanda-46)
	- [5. Protezione](#5-protezione)
		- [Domanda 5.1](#domanda-51)
		- [Domanda 5.2 (answered)](#domanda-52-answered)
		- [Domanda 5.3](#domanda-53)
		- [Domanda 5.4](#domanda-54)
		- [Domanda 5.5](#domanda-55)
		- [Domanda 5.6](#domanda-56)
		- [Domanda 5.7](#domanda-57)
		- [Domanda 5.8](#domanda-58)
		- [Domanda 5.9](#domanda-59)
	- [6. Paginazione e Memoria Virtuale](#6-paginazione-e-memoria-virtuale)
		- [Domanda 6.1](#domanda-61)
		- [Domanda 6.2](#domanda-62)
		- [Domanda 6.3 (answered)](#domanda-63-answered)
		- [Domanda 6.4](#domanda-64)
		- [Domanda 6.5](#domanda-65)
		- [Domanda 6.6](#domanda-66)
		- [Domanda 6.7](#domanda-67)
		- [Domanda 6.8](#domanda-68)
		- [Domanda 6.9](#domanda-69)
		- [Domanda 6.10](#domanda-610)
		- [Domanda 6.11](#domanda-611)
		- [Domanda 6.12](#domanda-612)
		- [Domanda 6.13](#domanda-613)
		- [Domanda 6.14](#domanda-614)
		- [Domanda 6.15](#domanda-615)
		- [Domanda 6.16](#domanda-616)
		- [Domanda 6.17](#domanda-617)
		- [Domanda 6.18](#domanda-618)
		- [Domanda 6.19](#domanda-619)
		- [Domanda 6.20](#domanda-620)
		- [Domanda 6.21](#domanda-621)
		- [Domanda 6.22](#domanda-622)
		- [Domanda 6.23](#domanda-623)
		- [Domanda 6.24](#domanda-624)
		- [Domanda 6.25](#domanda-625)
		- [Domanda 6.26](#domanda-626)
		- [Domanda 6.27](#domanda-627)
		- [Domanda 6.28](#domanda-628)
	- [7. Sistemi Multiprocesso e Processi](#7-sistemi-multiprocesso-e-processi)
		- [Domanda 7.1](#domanda-71)
		- [Domanda 7.2](#domanda-72)
		- [Domanda 7.3](#domanda-73)
		- [Domanda 7.4](#domanda-74)
		- [Domanda 7.5](#domanda-75)
		- [Domanda 7.6](#domanda-76)
		- [Domanda 7.7](#domanda-77)
		- [Domanda 7.8](#domanda-78)
		- [Domanda 7.9](#domanda-79)
		- [Domanda 7.10](#domanda-710)
		- [Domanda 7.11](#domanda-711)
		- [Domanda 7.12](#domanda-712)
		- [Domanda 7.13](#domanda-713)
		- [Domanda 7.14](#domanda-714)
	- [8. Realizzazione delle Primitive](#8-realizzazione-delle-primitive)
		- [Domanda 8.1](#domanda-81)
		- [Domanda 8.2](#domanda-82)
		- [Domanda 8.3](#domanda-83)
		- [Domanda 8.4](#domanda-84)
		- [Domanda 8.5](#domanda-85)
		- [Domanda 8.6](#domanda-86)
		- [Domanda 8.7](#domanda-87)
		- [Domanda 8.8](#domanda-88)
		- [Domanda 8.9](#domanda-89)
		- [Domanda 8.10](#domanda-810)
		- [Domanda 8.11](#domanda-811)
		- [Domanda 8.12](#domanda-812)
		- [Domanda 8.13](#domanda-813)
		- [Domanda 8.14](#domanda-814)
		- [Domanda 8.15](#domanda-815)
	- [9. Semafori](#9-semafori)
		- [Domanda 9.1](#domanda-91)
		- [Domanda 9.2](#domanda-92)
		- [Domanda 9.3](#domanda-93)
		- [Domanda 9.4](#domanda-94)
	- [10. Delay e Gestione del Tempo](#10-delay-e-gestione-del-tempo)
		- [Domanda 10.1](#domanda-101)
		- [Domanda 10.2](#domanda-102)
	- [11. Bus PCI](#11-bus-pci)
		- [Domanda 11.1](#domanda-111)
		- [Domanda 11.2](#domanda-112)
	- [12. I/O e Driver](#12-io-e-driver)
		- [Domanda 12.1](#domanda-121)
		- [Domanda 12.2](#domanda-122)
		- [Domanda 12.3](#domanda-123)
		- [Domanda 12.4](#domanda-124)
		- [Domanda 12.5](#domanda-125)
		- [Domanda 12.6](#domanda-126)
		- [Domanda 12.7](#domanda-127)
		- [Domanda 12.8](#domanda-128)
		- [Domanda 12.9](#domanda-129)
		- [Domanda 12.10](#domanda-1210)
		- [Domanda 12.11](#domanda-1211)
		- [Domanda 12.12](#domanda-1212)
		- [Domanda 12.13](#domanda-1213)
		- [Domanda 12.14](#domanda-1214)
	- [13. DMA (Direct Memory Access)](#13-dma-direct-memory-access)
		- [Domanda 13.1](#domanda-131)
		- [Domanda 13.2](#domanda-132)
		- [Domanda 13.3](#domanda-133)
		- [Domanda 13.4](#domanda-134)
		- [Domanda 13.5](#domanda-135)
		- [Domanda 13.6](#domanda-136)
		- [Domanda 13.7](#domanda-137)
		- [Domanda 13.8](#domanda-138)
		- [Domanda 13.9](#domanda-139)
		- [Domanda 13.10](#domanda-1310)
		- [Domanda 13.11](#domanda-1311)
		- [Domanda 13.12](#domanda-1312)
		- [Domanda 13.13 (answered)](#domanda-1313-answered)
		- [Domanda 13.15](#domanda-1315)
		- [Domanda 13.16](#domanda-1316)
		- [Domanda 13.17](#domanda-1317)
		- [Domanda 13.18](#domanda-1318)
		- [Domanda 13.19](#domanda-1319)
		- [Domanda 13.20](#domanda-1320)
	- [14. Architettura Moderna CPU](#14-architettura-moderna-cpu)
		- [Domanda 14.1 (answered)](#domanda-141-answered)
		- [Domanda 14.2](#domanda-142)
		- [Domanda 14.3](#domanda-143)
		- [Domanda 14.4](#domanda-144)
		- [Domanda 14.5](#domanda-145)
		- [Domanda 14.6](#domanda-146)
		- [Domanda 14.7](#domanda-147)
		- [Domanda 14.8](#domanda-148)
		- [Domanda 14.9](#domanda-149)
		- [Domanda 14.10](#domanda-1410)
		- [Domanda 14.11](#domanda-1411)
	- [Note per lo Studio](#note-per-lo-studio)

<div class="stop"></div>

## 1. Architettura di Base e Memoria

### Domanda 1.1 (answered)
**Domanda:** Nell'architettura CPU-Memoria-I/O che stiamo studiando, chi conosce cosa? Spieghi dettagliatamente la conoscenza e ignoranza di ciascun componente del sistema.

**Risposta:**
Nell'architettura classica CPU-Memoria-I/O, ogni componente ha una visione parziale del sistema, fondamentale per la separazione dei compiti e la sicurezza.

**CPU:**
> La CPU conosce solo i propri registri interni e può accedere alla memoria tramite indirizzi, ma non ha conoscenza diretta della struttura fisica della RAM o delle periferiche. La CPU invia segnali di lettura/scrittura e indirizzi, ma non "vede" cosa c'è oltre l'interfaccia di memoria.

**Memoria (RAM):**
> La memoria è un dispositivo passivo: non conosce la CPU né le periferiche. Si limita a rispondere alle richieste di lettura/scrittura sugli indirizzi che le vengono forniti. Non ha consapevolezza di chi stia accedendo o del significato dei dati.

**Periferiche/I/O:**
> Le periferiche sono progettate per rispondere a comandi specifici, ma non conoscono la CPU o la RAM. Interagiscono tramite registri di controllo e dati, e possono generare segnali di interruzione per notificare eventi alla CPU.

**Riferimento:**
> "La CPU comunica con la memoria e le periferiche tramite bus dedicati. Ogni componente è progettato per ignorare i dettagli interni degli altri, garantendo modularità e sicurezza."
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#architettura-cpu-memoria-io)*

**Esempio pratico:**
> Quando la CPU esegue un'istruzione di scrittura, invia un indirizzo e un dato sul bus. La RAM riceve la richiesta e memorizza il dato, senza sapere se proviene da un programma utente o dal sistema operativo. Analogamente, una periferica riceve comandi senza sapere chi li ha generati.

**Conclusione:**
Questa architettura a conoscenza limitata permette di realizzare sistemi scalabili, sicuri e facilmente espandibili.

---

### Domanda 1.2 (answered)
**Domanda:** Come viene gestito il flusso di controllo al momento dell'avvio del calcolatore? Cosa succede quando il contenuto della RAM è casuale?

**Risposta:**
Il flusso di controllo all'avvio del calcolatore è gestito attraverso una sequenza ben definita di passaggi che iniziano dalla ROM e portano all'esecuzione del sistema operativo, gestendo il problema critico del contenuto casuale della RAM.

**Il problema del contenuto casuale della RAM:**

**Problema fondamentale all'avvio:**
> Al'avvio del calcolatore però il contenuto della memoria **RAM** è _casuale_.
> È quindi necessario che il programma di `bootstrap`, ovvero quelle informazioni necessarie a inizializzare in maniera corretta l'`%rip`.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#21-flusso-di-controllo)*

**Soluzione tramite ROM e BIOS:**
> Il programma `bootstrap` deve essere salvato in una memoria **ROM** sulla quale il programma deve essere salvato.
>
> All'inizio della storia dei calcolatori il programma di `bootstrap` veniva caricato **manualmente** dagli operatori ad ogni accensione del calcolatore.
> La **ROM** permette di non dover fare più questa operazione, è infatti sufficente impostare che in fase di `/reset` la **CPU** vada a consultare quest'ultima. Il `BIOS` è contenuto in questa parte di programma.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#21-flusso-di-controllo)*

**Sequenza di avvio nei processori Intel:**

**Modalità di avvio progressive:**
> I processori _intel_ sono ancora oggi progettati per avviarsi a `16bit` in modalità non protetta.
> Via _software_ vengono poi portati in modalità protetta a `32bit`, in generale grazie ad un programma di `bootstrap` nel `BIOS`.
> Nel nostro caso sarà l'emulatore stesso ad effettuare questo primo passaggio.
>
> Tocca a noi però portare il processore nella modalità a `64bit`, e questo compito lo facciamo svolgere al programma `boot.bin` che può cedere il controllo al modulo `sistema`.
>
> *Fonte: [Sistemi Multiprocesso e Processi.md](./Sistemi%20Multiprocesso%20e%20Processi.md#242-avvio-sistema)*

**Processo di bootstrap dettagliato:**

**Il bootloader e il caricamento dei moduli:**
> Il programma `boot.bin` esegue una serie di allocazioni in memoria per permettere il corretto funzionamento della nostra macchina.
>
> Le righe 1-15 arrivano dal programma `boot.bin`:
> - Nelle righe 4–7 il programma `boot.bin` ci informa del fatto che il `bootloader` precedente (nel nostro caso `QEMU` stesso) ha caricato in memoria _tre file_, in particolare il file `build/sistema.strip4` all'indirizzo `0x114000`.
>
> *Fonte: [Sistemi Multiprocesso e Processi.md](./Sistemi%20Multiprocesso%20e%20Processi.md#242-avvio-sistema)*

**Esempio concreto della sequenza di avvio:**
Dal log di avvio del sistema possiamo vedere la sequenza completa:

> ```
> 1 | [INF] - Boot loader di Calcolatori Elettronici, v1.0
> 2 | [INF] - Memoria totale: 32 MiB, heap: 636 KiB
> 3 | [INF] - Argomenti: /home/gabrieledc/CE/lib/ce/boot.bin
> 4 | [INF] - Il boot loader precedente ha caricato 3 moduli:
> 5 | [INF] - - mod[0]: start=114000 end=12f580 file=build/sistema.strip
> 6 | [INF] - - mod[1]: start=130000 end=1414e0 file=build/io.strip
> 7 | [INF] - - mod[2]: start=142000 end=147400 file=build/utente.strip
> 8 | [INF] - Copio mod[0] agli indirizzi specificati nel file ELF:
> 9 | [INF] - - copiati 108560 byte da 114000 a 200000
> 10 | [INF] - - copiati 970 byte da 12edb8 a 21bdb8
> 11 | [INF] - - azzerati ulteriori 79030 byte
> 12 | [INF] - - entry point 200178
> 13 | [INF] - Creata finestra sulla memoria centrale: [ 1000, 2000000)
> 14 | [INF] - Creata finestra per memory-mapped-IO: [ 2000000, 100000000)
> 15 | [INF] - Attivo la modalita' a 64 bit e cedo il controllo a mod[0]...
> ```
>
> *Fonte: [Sistemi Multiprocesso e Processi.md](./Sistemi%20Multiprocesso%20e%20Processi.md#242-avvio-sistema)*

**Controllo del flusso di esecuzione:**

**Principio fondamentale:**
> Abbiamo più volte detto che la **CPU** non fa altro che leggere e eseguire le istruzioni una alla volta.
> Per capire però dove recuperare una nuova istruzione una volta eseguita quella precedente va a consultare l'_istruction Pointer_ `%rip` che viene aggiornato dell'operazione precedente.
>
> Il controllo **è unico** e può essere solo scambiato tra i vari stati della **CPU**, a loro volta scanditi dal _programma in esecuzione_.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#21-flusso-di-controllo)*

**Attivazione della modalità 64-bit:**
Il passaggio finale alla modalità a 64-bit avviene attraverso la paginazione:

> ```x86asm
> ; settiamo il bit 31 di CR0
>     MOVl %cr0, %eax
>     ORl $0x80010000, %eax    // paging & write-protect
>     MOVl %eax, %cr0
> ; ora la modalità a 64 bit è attiva ...
> ```
>
> *Fonte: [Memoria Virtuale nel Nucleo.md](./Memoria%20Virtuale%20nel%20Nucleo.md)*

**Gestione della memoria durante l'avvio:**

**Inizializzazione delle traduzioni di memoria:**
> Le traduzioni della parte `sistema/condivisa` sono create dal _bootloader_ **prima di abilitare la paginazione** tramite la funzione `crea_finestra_FM()`.
>
> La modifica al _bootstrap_ di un processo per creare questa opzione è in realtà abbastanza banale, in quanto all'accensione la `MMU` è disattivata, e la **CPU** utilizza direttamente gli indirizzi **fisici**.
>
> *Fonte: [Memoria Virtuale nel Nucleo.md](./Memoria%20Virtuale%20nel%20Nucleo.md) e [Paginazione.md](./Paginazione.md#331-traduzioni-identità)*

**Inizializzazione del sistema:**
Una volta completato il bootstrap, il sistema inizializza i suoi componenti:

> - Nelle righe 36-37 vengono creati i primi processi di sistema
> - Alla riga 38 vediamo che viene inizializzato l'`APIC`.
> - Nella riga 40 veniamo informati dell'inizializzazione dello _heap di sistema_ (riutilizzando lo spazio occupato da `boot.bin`).
>
> *Fonte: [Sistemi Multiprocesso e Processi.md](./Sistemi%20Multiprocesso%20e%20Processi.md#242-avvio-sistema)*

In sintesi, il flusso di controllo all'avvio è gestito attraverso una catena di responsabilità: ROM/BIOS → bootloader → boot.bin → modulo sistema, dove ogni componente ha il compito di inizializzare il successivo e trasferirgli il controllo, risolvendo il problema del contenuto casuale della RAM attraverso l'uso di memoria non volatile (ROM) per i programmi di bootstrap.

---

### Domanda 1.3 (answered)
**Domanda:** Nell'architettura CPU-Memoria-I/O, descriva dettagliatamente come avviene la comunicazione tra CPU e RAM. Cosa sono i segnali `/be` (Byte Enabler) e come vengono utilizzati nelle operazioni di scrittura?

**Risposta:**
La comunicazione tra CPU e RAM nell'architettura CPU-Memoria-I/O avviene attraverso un sistema di bus strutturato con specifici segnali di controllo, dove i Byte Enabler (`/be`) svolgono un ruolo cruciale per permettere operazioni selettive sui singoli byte.

**Architettura generale CPU-Memoria-I/O:**

**Struttura fondamentale:**
> Andremo a studiare un'architettura Architettura CPU - Memoria (RAM e ROM) - I/O.
> Questa architettura è stata progettata con lo scopo di **eseguire software**
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md)*

**Struttura del bus di comunicazione:**

**Composizione del bus CPU-RAM:**
> **CPU** e **RAM** sono collegate da un _bus_ che è composto da:
> - `D`: Rappresenta le **Linee di indirizzo**. In teoria sarebbero `64` ma nei processori _Intelx86_ il massimo è `57`. Nei processori comuni tendenzialmente questi fili però sono "solamente" `48`. Questo perché $2^{64}$ indirizzi di memoria sono decisamente troppi per un calcolatore comune.
> - `A`: indica il **numero di riga** in **RAM** alla quale vogliamo accedere.
> - `C`: rappresenta i fili che contengolo le variabili di controllo (`/mw`, `/mr`, ...)
> - `/be`: sono i _Byte Enabler_. Ne esiste uno per ogni byte di _una riga_. Vengono utilizzati principalmente in scrittura, perché permettono di poter modificare solamente i singoli bit in un indirizzo.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#25-comunicazione-cpu-memoria)*

**Interfaccia dei chip di memoria:**

**Collegamenti del singolo chip di RAM:**
> Il singolo chip di **RAM** avrà come collegamenti possibili:
> - `/s`: select
> - `A`: indirizzo
> - `/r`: comando di lettura
> - `/w`: comando di scrittura
> - `D`: dati, su `8bit`
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#25-comunicazione-cpu-memoria)*

**I segnali Byte Enabler (`/be`):**

**Definizione e funzione:**
> Ciò significa che dato un indirizzo `A[63:0]`, il numero di riga verrà identificato dai bit `A[63:3]`. I restanti `A[2:0]` rappresentano l'offset all'interno della riga, e vengono chiamati **_Byte Enabler_** `BE`.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md)*

**Utilizzo nelle operazioni di scrittura:**
I Byte Enabler permettono di effettuare operazioni selettive sui singoli byte di una riga di memoria, evitando di dover riscrivere l'intera riga quando si vuole modificare solo una parte.

**Implementazione hardware dei Byte Enabler:**

**Collegamento dei chip di memoria:**
Nell'implementazione hardware, ogni chip di memoria è collegato attraverso un sistema che utilizza i Byte Enabler per determinare quale parte della riga deve essere effettivamente scritta:

> ```v
> assign w_ = W_;
> assign r_ = R_;
> 
> assign Di = D[8*i + 7 : 8*i];
> // Il padding corretto del bus dei dati
> 
> assign Ai = A[(k-3)-1 : 0];
> /*
> * k-3 perché ogni riga di indirizzo contiene 8 indirizzi,
> * Se tutti i chip devono memorizzare 2^k byte, ognuno ne memorizzerà:
> *   2^k / 8 -> 2^(k-3) byte
> * Ciò implica che
> */
> wire mask_; assign mask_ = A[n - 1 : n - k] ^ indirizzo_di_riga;
> /*
> * Metto in OR (sono attivi bassi) :
> *  - Il bit corrispettivo del Byte Enabler
> *  - XOR tra la parte alta di A e l'indirizzo della riga
> *
> * Questo si fa per determinare se la regione è quella interpellata
> */
> assign s_ = (BE_[i] | mask_);
> ```
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#25-comunicazione-cpu-memoria)*

**Esempio di utilizzo nel bus PCI:**

**Byte Enabler nel contesto PCI:**
I Byte Enabler sono utilizzati anche in altri contesti sistemici, come nel bus PCI:

> | `BE#[3:0]` | uscita | ingresso | Fungono da _byte-enabler_ nelle fasi di trasferimento (`BE#[3:0]`) |
>
> *Fonte: [PCI.md](./PCI.md)*

**Caratteristiche delle operazioni di memoria:**

**Formato delle istruzioni Intel x86:**
> Il formato delle istruzioni _Intelx86_ può avere al massimo **1 operando esplicito in memoria**.
>
> Tuttavia è possibile operare con due operatori in memoria, attraverso **operazioni che hanno accessi impliciti**.
> Alcuni esempi sono la `MOVS`, `PUSH (%rdi)`, `POP(%rdi)`.
>
> Una qualsiasi informazione che va nella memoria possiede due proprietà:
> - **Indirizzo**: indirizzo della prima locazione di memoria desiderata
> - **Dimensione**: talvolta si deduce dai registri, talvolta necessita di essere esplicitata con il _suffisso_, indica a quanti byte vogliamo accedere.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#25-comunicazione-cpu-memoria)*

**Dimensioni degli accessi in memoria:**

**Tipi di accesso supportati:**
> Nelle memorie per processori _Intelx86_ che vedremo le dimensioni degli accessi in memoria sono i seguenti:
>
> | | `B` | `W` | `L` | `Q` |
> |:---:|:---:|:---:|:---:|:---:|
> | Byte | `1` | `2` | `4` | `8` |
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#23-memoria)*

**Importanza degli allineamenti:**

**Necessità di accessi multipli per dati non allineati:**
> Data questa configurazione risulta chiara l'importanza degli allineamenti.
>
> Se volessimo infatti accedere a indirizzi non allineati è **necessario** fare **2 accessi**.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#25-comunicazione-cpu-memoria)*

In sintesi, la comunicazione CPU-RAM avviene attraverso un bus strutturato con linee dati, indirizzi e controllo, dove i segnali `/be` (Byte Enabler) permettono operazioni selettive sui singoli byte, ottimizzando le prestazioni ed evitando riscritture non necessarie di intere righe di memoria. Questo meccanismo è fondamentale per l'efficienza del sistema di memoria e viene implementato a livello hardware attraverso logiche di selezione che determinano quali chip di memoria devono essere attivati per ciascuna operazione.

---

### Domanda 1.4 (answered)
**Domanda:** Spieghi il problema degli accessi non allineati alla memoria. Come viene gestito dall'hardware il caso di un'operazione `MOVQ 4097, %RAX` e quale ruolo ha il μ-codice della CPU?

**Risposta:** 
Gli accessi non allineati alla memoria rappresentano un problema fondamentale nell'architettura dei calcolatori perché violano il principio di allineamento naturale degli oggetti in memoria.

**Allineamento naturale degli oggetti:**
Un oggetto si dice allineato naturalmente se il suo indirizzo è divisibile per la sua dimensione. Formalmente:
> Un oggetto $o$ si dice _allineato naturalmente_ se $|o|_{sizeof(o)} = 0$
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#243-allineamento-naturale)*

**Tipi di allineamento richiesti:**
- Un `BYTE` (1 byte) può essere posizionato a qualsiasi indirizzo
- Un `WORD` (2 bytes) deve essere allineato a indirizzi pari (divisibili per 2)
- Un `LONG` (4 bytes) deve essere allineato a indirizzi divisibili per 4
- Un `QUAD` (8 bytes) deve essere allineato a indirizzi divisibili per 8

**Organizzazione della memoria RAM:**
> Nella memoria RAM possiamo identificare una regione come uno spazio di `8Byte`.
> Assegneremo quindi ad ognuna un numero, detto **numero di riga**, che la identificherà.
> 
> Ciò significa che dato un indirizzo `A[63:0]`, il numero di riga verrà identificato dai bit `A[63:3]`. I restanti `A[2:0]` rappresentano l'offset all'interno della riga, e vengono chiamati **_Byte Enabler_** `BE`.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#regione-e-confine)*

**Analisi del caso specifico: `MOVQ 4097, %RAX`:**
L'operazione `MOVQ 4097, %RAX` richiede la lettura di 8 byte consecutivi a partire dall'indirizzo 4097.

**Scomposizione dell'indirizzo 4097 (0x1001):**
- Numero di riga: `A[63:3]` = 512 (0x200)
- Offset nella riga: `A[2:0]` = 1

**Il problema dell'accesso non allineato:**
Un `QUAD` (8 bytes) che inizia all'offset 1 si estende fino all'offset 8, ma ogni riga contiene solo gli offset da 0 a 7. Questo significa che i dati richiesti si trovano **a cavallo di due righe consecutive**.

**Gestione hardware:**
> Data questa configurazione risulta chiara l'importanza degli allineamenti.
> Se volessimo infatti accedere a indirizzi non allineati è **necessario** fare **2 accessi**.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#25-comunicazione-cpu-memoria)*

**Processo di gestione hardware:**
1. **Primo accesso:** Legge la riga 512 per ottenere i byte agli offset 1, 2, 3, 4, 5, 6, 7 (7 bytes)
2. **Secondo accesso:** Legge la riga 513 per ottenere il byte all'offset 0 (1 byte rimanente)

**Ricomposizione dei dati:**
> Inoltre potrebbe diventare necessario sistemare il padding dei byte, in quanto quelli all'indirizzo precedente si trovano nella regione delle _MSB_, anche se per quello che ci riguarda sono nella _LSB_.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#25-comunicazione-cpu-memoria)*

**Il ruolo del μ-codice della CPU:**
> Tutte queste operazioni vengono eseguite non dal software (l'operazione `MOVQ 4097, %RAX` di fatto fa tutto in una riga), ma dall'**hardware**, in particolare nel _$\mu$-codice che implementa l'accesso in memoria_ che si trova nella **CPU**.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#25-comunicazione-cpu-memoria)*

**Operazioni gestite dal μ-codice:**
1. **Rilevare** che l'accesso è non allineato
2. **Scomporre** l'operazione singola in due accessi separati
3. **Gestire** i due accessi alla memoria consecutivi
4. **Ricomporre** i dati letti nelle posizioni corrette
5. **Presentare** il risultato finale come se fosse stato un singolo accesso

**Impatto sulle prestazioni:**
Gli accessi non allineati hanno un costo significativo perché:
- Richiedono **doppi accessi** alla memoria
- Aumentano il **traffico sul bus**
- Possono causare **miss aggiuntivi** nella cache
- Richiedono **elaborazione extra** da parte del μ-codice

Per questo motivo, i compilatori cercano sempre di allineare naturalmente gli oggetti in memoria, e i programmatori devono prestare attenzione all'allineamento delle strutture dati per ottenere prestazioni ottimali.

---
<div class="stop"></div>

---

## 2. Memoria Cache

### Domanda 2.1 (answered)
**Domanda:** A che serve la Cache e come funziona? Descriva i principi di funzionamento fondamentali.

**Risposta:** 
La memoria cache è una soluzione hardware fondamentale per risolvere il problema della disparità di velocità tra processore e memoria RAM.

**Problema che risolve la cache:**
> La **RAM** è estrememante lenta rispetto al processore, circa 200/300 volte più lenta, ciò mette in attesa il processore.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#27-memoria-cache)*

**Soluzione technologica:**
> Un modo per avere **RAM** più veloci è quello di utilizzare le **RAM Statiche** invece di quelle _dinamiche_.
> Le **RAM Statiche** conservano l'informazione tramite `Flip-Flop`, e sono realizzabili con 6/7 transistor.
> Le **RAM Dinamiche** invece utilizzano microcondensatori che necessitano che l'informazione venga periodicamente "rinfrescata".

| RAM Dinamiche | RAM Statiche |
| :-----------: | :----------: |
|    Grandi     |   Piccole    |
|  Economiche   |   Costose    |
|     Lente     |    Veloci    |

> Esiste tuttavia un modo per poter utilizzare **RAM** _grandi, economiche e veloci_.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#27-memoria-cache)*

**Principi di località:**
La cache si basa sui **principi di località**, che sono osservazioni statistiche sul comportamento dei programmi:

> Il codice infatti si distribuisce in locazioni di memoria sequenziali, e, statisticamente, **raramente** effettua salti casuali tra istruzioni.
> Su questa assunzione di base si fondano i due **_Principi di Località_**:
> 
> **Principio di località Temporale**: visto un dato è probabile che molto presto si voglia utilizzare di nuovo.
> 
> **Principio di località Spaziale**: visto un indirizzo è probabile che a breve ci si ritorni.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#27-memoria-cache)*

**Funzionamento del controllore cache:**
> La memoria _cache_ funziona proprio basandosi su questi principi.
> Infatti quando eseguiamo diversi accessi alla **RAM**, la _cache_ sarà in ascolto di letture e scritture, salvando in locale i dati che i principi dicono che serviranno.
> 
> L'esecuzione della _cache_ è gestita da un **_controllore_** che lavora in maniera totalmente trasparente, **senza che il processore e il programmatore sappiano della sua esistenza**.
> Tuttavia il programmatore può _approfittare dei principi_, affinché possa sfruttare al massimo la _cache_.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#27-memoria-cache)*

**Meccanismo di funzionamento:**
> Il controllore verifica che un dato richiesto dalla CPU sia già stato memorizzato.
> Se lo è stato lo invia immediatamente, altrimenti effettua una lettura in **RAM** e lo invia alla **CPU**.
> Prima di inviarlo però lo salva localmente, eventualmente rimpiazzando altri dati che erano già salvati.
> La scelta di quale dato sovrascrivere può essere determinata automaticamente dall'architettura (come nel nostro caso) oppure può utilizzare diversi meccanismi di selezione specifici dell'architettura stessa.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#27-memoria-cache)*

**Hit e Miss:**
> Quando il processore richiede una locazione di memoria, si effettua un controllo per verificare che si trovi o meno nella _cache_.
> Il segnale di `hit` indica che la memoria si trova già nella _cache_, perciò è sufficente leggere quella.
> 
> Il segnale di `miss` indica invece che la memoria non è nella _cache_, perciò va recuperato dalla **RAM** per poter essere letto.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#271-cache-ad-indirizzamento-diretto)*

**Politiche di scrittura:**
In caso di scrittura con `hit` abbiamo due possibili politiche:
- **`Write Through`**: scrive il nuovo valore sia in _cache_ che in **RAM**
- **`Write Back`**: scrive il nuovo valore solo nella _cache_

Anche in caso di `miss` la scrittura ha due possibili politiche:
- **`Write Allocate`**: copia l'elemento dalla **RAM** nella _cache_ prima della modifica, e poi lo ritrasmette aggiornato
- **`Write No-Allocate`**: effettua l'aggiornamento **solo** in **RAM**, senza salvare nulla in _cache_

**Ottimizzazione per località spaziale:**
> Il motivo per il quale, data una riga, recuperiamo in cache tutta la sezione dov'è contenuta è perché, per il principio di località, è probabile che il processore richieda in un secondo momento locazioni vicine (_località spaziale_).
> Inoltre, se il tempo di lettura di una riga fosse $t$, quella di lettura di un blocco è un tempo $\ll 8t$.
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#271-cache-ad-indirizzamento-diretto)*

**Trasparenza:**
> La memoria cache lavora _solo_ sulla **RAM**, non ha alcun senso che lavori per l'_I/O_, poiché manca il principio base (_I/O_ ha effetti collaterali voluti).
>
> *Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#27-memoria-cache)*

In sintesi, la cache è una memoria piccola, veloce e costosa che funge da buffer intelligente tra CPU e RAM, sfruttando i principi di località per predire quali dati serviranno al processore, migliorando drasticamente le prestazioni del sistema.

---

### Domanda 2.2
**Domanda:** I principi di località valgono sempre? Quando sono rispettati i principi di località?

**Risposta:** 
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 2.3
**Domanda:** Come funziona la cache a indirizzamento diretto? Descriva l'implementazione.

**Risposta:** 
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 2.4
**Domanda:** Come è fatta una cacheline? Quali informazioni contiene e come viene gestita?

**Risposta:** 
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 2.5
**Domanda:** Descriva le politiche di sostituzione delle cacheline e i loro vantaggi/svantaggi.

**Risposta:** 
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 2.6 (answered)
**Domanda:** Come funziona la cache associativa per insiemi? Confronti con quella a indirizzamento diretto.

**Risposta:**
La cache associativa per insiemi è un'evoluzione della cache a indirizzamento diretto che risolve il problema dei conflitti tra cacheline allineate naturalmente.

**Cache a indirizzamento diretto - problemi:**

> Con questo tipo di _cache_, detta **_ad indirizzamento diretto_**, si possono generare conflitti tra sezioni.
> In particolare, le sezioni che possono fare conflitto in una stessa locazione sono ${\dim{(\mathbf{RAM})} \over \dim{(\mathbf{cache})}}$, ovvero quelle **allineate naturalmente** a `l`, con `l` che indica il numero di _cache line_ disponibili.

> Questo tipo di _cache_ è particolarmente poco efficente quando cerchiamo di accedere a due _cacheline_ in memoria allineate naturalmente alla dimensione della _cache_.
> In questo caso ogni accesso causa una `miss`, proprio perché i due indirizzi collidono.

*Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#271-cache-ad-indirizzamento-diretto)*

**Funzionamento della cache associativa per insiemi:**

> Si basano sulle _cache ad indirizzamento diretto_.
> Infatti non sono altro che più cache allineate tra di loro:
> 
> L'esempio a destra è con due _cache_.
> 
> Si utilizzano le due cache in parallelo, in caso di conflitti, andremo a sovrascrivere la _cacheline_ che non si utilizza da più tempo.

*Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#272-cache-associative-ad-insiemi)*

**Gestione della sostituzione - Registro LRU:**

> Oltre alle cache, si introduce anche un ulteriore registro `R` che contiene tanti bit quanti sono necessari per ricordare l'ordinamento delle scritture.
> 
> In caso di due vie in `R` è sufficente `1bit`, che codifica quale delle due _cache_ non si utilizza da più tempo in quella _line_.
> In caso di quattro vie il registro viene chiamato `LRU` e contiene `5bit`.
> 
> Tuttavia, nel processore _x86_, è stato implementato uno `pseudo-LRU` a `3bit`

*Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#272-cache-associative-ad-insiemi)*

**Limitazioni della cache associativa per insiemi:**

> Tuttavia anche con il registro `LRU` è possibile generare sempre `miss`.
> Basta infatti effettuare un accesso in più di quelli possibili in parallelo, ad esempio se avessimo quattro cache e facessimo l'accesso a 5 linee allineate, genereremmo sempre una `miss`.

*Fonte: [Memoria e Periferiche.md](./Memoria%20e%20Periferiche.md#272-cache-associative-ad-insiemi)*

**Vantaggi principali del confronto:**
- **Cache a indirizzamento diretto**: Semplice, veloce, ma soffre di conflitti quando si accede a indirizzi allineati naturalmente
- **Cache associativa per insiemi**: Risolve i conflitti grazie alle multiple "vie" parallele e al sistema LRU, ma aumenta la complessità hardware

---

### Domanda 2.7
**Domanda:** Cosa sono gli algoritmi di sostituzione nella cache? Spiega LRU e pseudo-LRU.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 2.8
**Domanda:** Cosa sono le politiche write-through e write-back? Quando si usano?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 2.9
**Domanda:** Come interagisce la cache con la memoria virtuale e la paginazione?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---
<div class="stop"></div>

---

## 3. Interruzioni

### Domanda 3.1 (answered)
**Domanda:** Spieghi il problema di Dijkstra relativo alla stampa e come le interruzioni lo risolvono. Perché un approccio con `checkFlag()` troppo frequente o troppo raro non è ottimale?

**Risposta:**
Il problema di Dijkstra è un classico esempio che dimostra la necessità delle interruzioni per gestire efficacemente la sincronizzazione tra CPU e periferiche.

**Il problema originale:**
> Ipotizziamo di avere una tabella contenente due indici:
> - Nel primo si trova un numero $x$ crescente
> - Nel secondo si trova il valore di una funzione $f(x)$ calcolata sul valore di $x$ attuale.
> 
> Vorremmo che venissero stampati le coppie valore $x$-$f(x)$.
>
> *Fonte [Interruzioni.md](./Interruzioni.md#2-interruzioni)*

**Architettura della stampante:**
> La stampa degli elementi è gestita tramite una stampante con due registri:
> - `TBR`: contiene il valore di $f(x)$
> - `STS`: _handshake_, contiene un flag che indica che la stampa di $f(x)$ è avvenuta con successo e si può inserire un nuovo valore in `TBR`.

**Approccio ingenuo con polling:**
> Un approccio al problema potrebbe essere questo:
> 1. Calcolo $f(x_1)$
> 2. Lo inserisco nella stampante
> 3. Attendo che la stampa avvenga spettando `checkFlag()`
> 4. Calcolo $f(x_2)$
> 5. ...
> 
> Questo approccio però perde del tempo durante l'attesa di `checkFlag()`.
> In particolare potremmo utilizzare questo tempo per precalcolare le $f(x_i)$ successive.

**Problemi del polling con frequenza inadeguata:**

*Troppo raro:*
```cpp
checkFlag();
for(int i = 0; i < 1000000; ++i)
	a += i;
checkFlag();
```
- **Problema**: La stampante potrebbe completare la stampa molto prima del prossimo controllo
- **Conseguenza**: Spreco di tempo prezioso che potrebbe essere usato per calcoli utili

*Troppo frequente:*
```cpp
for(int i = 0; i < 1000000; ++i){
	checkFlag()
	a += i;
}
```
- **Problema**: Troppo tempo speso a controllare il flag invece di fare calcoli produttivi
- **Conseguenza**: Overhead eccessivo che rallenta l'elaborazione

**Soluzione con interruzioni:**
> Implementiamo quindi una modifica **<u>hardware</u>** che ci permetta poi di implementare le _routine_ degli eventi in _software_.

**Meccanismo hardware:**
> Quello che possiamo fare per supportare gli eventi di questa interfaccia è collegare fisicamente il bit della stampante alla **CPU** e aggiungere una $\mu$-istruzione che controlla il bit al termine di ogni istruzione.

**Vantaggi delle interruzioni:**
1. **Efficienza**: La CPU può continuare a calcolare le funzioni $f(x)$ senza perdere tempo in polling
2. **Reattività**: Risposta immediata quando la stampante è pronta
3. **Ottimizzazione**: Utilizzo ottimale delle risorse di sistema

**Gestione della singola richiesta:**
> Il processore vede continuamente il segnale `READY` come settato ricevendo di fatto infinite richieste, quando in realtà vogliamo solamente una richiesta singola.
> 
> Per rimediare a questi problemi è sufficente inserire un **generatore di impulsi** e un **`FF-SR`** che verrà resettato quando la richiesta sarà stata già presa in **attenzione**.

**Controllo del flusso delle interruzioni:**
> Per quanto riguarda la gestione delle interruzioni durante _routine_, nel processore _intelx86_ esiste un **flag aggiuntivo** in `RFLAG`, chiamato `IF` (_Interrupt Flag_). Se il bit è resettato, il processore **non accetta nuove richieste** finché non ha terminato quella attuale.

Questo approccio risolve elegantemente il problema di Dijkstra permettendo alla CPU di massimizzare l'utilizzo computazionale mentre mantiene una sincronizzazione perfetta con le periferiche.

---

### Domanda 3.2 (answered)
**Domanda:** Descriva il meccanismo hardware delle interruzioni APIC. Come viene risolto il problema delle interruzioni a più sorgenti?

**Risposta:**
L'APIC (Advanced Programmable Interrupt Controller) è un controllore delle interruzioni che risolve il problema della gestione di più sorgenti di interrupt in modo elegante ed efficiente.

**Architettura hardware dell'APIC:**

> Il _controllore_ è collegato alle periferiche tramite tre fili, ognuna collegata ad un **_piedino noto dalle specifiche_**.
> Nel nostro calcolatore i dispositivi rilevanti sono connessi ai seguenti piedini
> - **Tastiera** ↔ `1`
> - **Timer** ↔ `2`
> - **Hard Disk** ↔ `14`
> 
> Quando uno di questi segnali viene settato l'`APIC` invia alla **CPU** un segnale tramite un suo registro interno chiamato `INTR` (_INTervall Request_), inizializzando un _handshake_.

*Fonte: [Interruzioni.md](./Interruzioni.md#21-interruzioni-a-più-sorgenti---apic)*

**Meccanismo di gestione delle interruzioni multiple:**

L'APIC risolve il problema delle interruzioni a più sorgenti attraverso diversi registri specializzati da 256 bit:

> Per gestire le richieste di interruzione, l'`APIC`, oltre a `EOI`, possiede altri due registri a `256bit`:
> - `ISR` (_In Service Register_): conserva informazioni relative ai tipi accettati dalla **CPU** e non ancora terminati.
> - `IRR` (_Interrupt Request Register_): conserva informazioni relative alle richieste dei tipi non ancora accettati.

*Fonte: [Interruzioni.md](./Interruzioni.md#21-interruzioni-a-più-sorgenti---apic)*

**Sistema di priorità e tipizzazione:**

Il programmatore assegna un **tipo** (8 bit) a ogni piedino dell'APIC:

> Il programmatore ha quindi il compito di assegnare una **precedenza** alle varie richieste, e lo fa tramite il **tipo**.
> 
> Quando assegna un tipo il programmatore ha `8bit`, dove i 4 più significativi indicano la _classe di precedenza_.
> 
> Se arriva una nuova richiesta che ha _classe strettamente maggiore_ l'`APIC` invierà una **nuova richiesta**, negli altri casi attenderà `EOI`, per poi inviare la successiva richiesta con classe più alta in `IRR`.

*Fonte: [Interruzioni.md](./Interruzioni.md#211-gestione-più-richieste)*

**Protocollo di handshake:**

> Per permettere di capire chi è la sorgente del segnale, **il programmatore** associa ad ogni piedino del controllore `APIC` un _tipo_, ovvero una codifica su `8bit`.
> 
> Nel momento in cui la **CPU** accetta la richiesta, si prepara inviando il segnale di _handshake_ tramite il filo `INTA`: _INTervall Acknowledge_.
> 
> Successivamente l'`APIC` carica il tipo sul _bus_ così che la **CPU** lo possa leggere.

*Fonte: [Interruzioni.md](./Interruzioni.md#21-interruzioni-a-più-sorgenti---apic)*

**Configurazione software dell'APIC:**

Dal file [`IO.md`](./IO.md#3-modulo-io):

```cpp
// Associazione irq->tipo (tramite l'APIC)
apic::set_VECT(irq, tipo);
apic::set_MIRQ(irq, false);  // abilita l'interruzione
gate_init(tipo, routine);    // associa routine al tipo
```

L'APIC risolve così il problema delle interruzioni multiple attraverso: vectorizzazione delle interruzioni per identificare la sorgente, sistema di priorità basato sui tipi, registri ISR/IRR per tracking delle interruzioni, e protocollo EOI per la sincronizzazione.

---

### Domanda 3.3 (answered)
**Domanda:** Spieghi il ruolo dei registri ISR (In Service Register) e IRR (Interrupt Request Register) nell'APIC. Come funziona il meccanismo di EOI (End Of Interrupt)?

**Risposta:**
I registri ISR e IRR sono componenti fondamentali dell'APIC per la gestione delle interruzioni multiple e la loro sincronizzazione.

**Funzione dei registri APIC:**
> Per gestire le richieste di interruzione, l'`APIC`, oltre a `EOI`, possiede altri due registri a `256bit`:
> - `ISR` (_In Service Register_): conserva informazioni relative ai tipi accettati dalla **CPU** e non ancora terminati.
> - `IRR` (_Interrupt Request Register_): conserva informazioni relative alle richieste dei tipi non ancora accettati.
>
> *Fonte: [Interruzioni.md](./Interruzioni.md#21-interruzioni-a-più-sorgenti---apic)*

**Dispositivi collegati:**
> Nel nostro calcolatore i dispositivi rilevanti sono connessi ai seguenti piedini
> - **Tastiera** ↔ `1`
> - **Timer** ↔ `2`
> - **Hard Disk** ↔ `14`

**Meccanismo di handshake:**
> Quando uno di questi segnali viene settato l'`APIC` invia alla **CPU** un segnale tramite un suo registro interno chiamato `INTR` (_INTervall Request_), inizializzando un _handshake_.

**Meccanismo EOI (End Of Interrupt):**
> Per evitare comportamenti indesiderati da parte dell'`APIC` è importante che questo `bit` venga settato **quando tutta la routine è terminata** e non c'è altro da fare.
> Se così non fosse, il controllore potrebbe reinviare segnali di interruzioni su eventi già gestiti.

**Esempio pratico nel codice:**
Dal file [`IO.md`](./IO.md#3-modulo-io) - Configurazione APIC:
```cpp
// Associazione irq->tipo (tramite l'APIC)
apic::set_VECT(irq, tipo);
// Smascheriamo le richieste irq nell'APIC
apic::set_MIRQ(irq, false);
```

E nell'handler:
```x86asm
a_wfi:
	CALL salva_stato
	CALL apic_send_EOI  ; ← Invio EOI all'APIC
```

**Funzionamento dettagliato:**
1. **IRR**: Tiene traccia delle richieste ricevute ma non ancora elaborate
2. **ISR**: Tiene traccia delle interruzioni attualmente in elaborazione
3. **EOI**: Segnala la fine dell'elaborazione e permette all'APIC di elaborare nuove richieste

---

### Domanda 3.4
**Domanda:** Descriva il funzionamento delle interruzioni e la scrittura delle routine. Come mai si usa `int` e non `call` per le interruzioni?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 3.5 (answered)
**Domanda:** Come è fatto un gate della IDT? Da dove viene preso il valore del nuovo `%rsp` se si cambia pila mentre si attraversa un gate?

**Risposta:**
I gate della IDT sono strutture hardware fondamentali per la gestione delle interruzioni e il cambio di contesto nei processori Intel, contenenti informazioni cruciali per la protezione e la transizione tra livelli di privilegio.

**Struttura di un gate della IDT:**
> Ogni _gate_ della `IDT` occupa `16Byte` e contiene le segueni informazioni:
> - Il puntatore alla `Routine` a cui saltare (`8 Byte`)
> - `P` (_Presenza_): indica se la riga contiene bit significativi
> - `I/T`: indica se il _gate_ è di tipo _Interrupt_ (azzera `IF`) o _Trap_ (mantiene `IF` invariato).
> - `L` (_Livello_): indica il _livello di privilegio_ al quale portare il processore **dopo** aver passato il _gate_. Nel nostro caso sarà sempre settato a `sistema`.
> - `DPL` (_Descriptor Privilege Level_): specifica il **livello di privilegio minimo** che deve avere il processore **prima** di passare il gate.
>
> *Fonte: [Protezione.md](./Protezione.md#22-passaggi-tra-contesti)*

**Funzione dei campi principali:**

**Campo DPL (Descriptor Privilege Level):**
> Può vietare l'utilizzo di alcuni gate attraverso l'istruzione `INT` generando un'_eccezione di protezione_ `13`. 
> I programmatori di sistema possono settarlo come:
> - `sistema`: nei _gate_ delle _interruzioni esterne_, così che possano essere attraversati solo da codice protetto
> - `utente`: nei _gate_ delle _primitive_, per permetterne l'utilizzo da parte degli utenti
>
> *Fonte: [Protezione.md](./Protezione.md#22-passaggi-tra-contesti)*

**Meccanismo di attraversamento del gate:**
Quando il processore attraversa un gate della IDT, segue una sequenza precisa:

> 1. Innanzitutto il processore si procura il _tipo_ dell'interruzione
> 2. Verifica se il bit `P` associato al tipo è zero, generando un'eccezione di _gate non presente_ `11` in caso positivo
> 3. Se sta gestendo una _interruzione software_ o `int3`, confronta il livello corrente con il campo `DPL` del gate.
> 4. Altrimenti, confronta `CS` con `L`. Se `L` è **inferiore**, si genera ancora un'_eccezione di protezione_ `13`.
>
> *Fonte: [Protezione.md](./Protezione.md#22-passaggi-tra-contesti)*

**Cambio di pila e origine del nuovo `%rsp`:**

**Necessità del cambio pila:**
> Il cambio di pila è **_necessario_**, è ha due motivazioni:
> - Il processore deve garantire di poter scrivere le 5 `long word` senza sovrascrivere altre cose, e non può quindi fidarsi di `RSP` che è completamente a servizio dell'utente.
> - Queste informazioni sono salvate nella memoria di sistema, in modo che l'utente **non le possa corrompere**.
>
> *Fonte: [Protezione.md](./Protezione.md#22-passaggi-tra-contesti)*

**Meccanismo del cambio pila:**
> 5. Negli altri casi, il processore salva in un registro di appoggio (chiamiamolo `SRSP`) il contenuto corrente di `RSP`
> 6. Se `CS` è diverso da `L` esegue un _cambio di pila_ (_pila sistema/utente_ nel nostro caso), caricando un nuovo valore in `RSP`

**Origine del nuovo `%rsp` - Il TSS:**
> Nei primi processori _intel_ ogni _job_ aveva un proprio **segmento** di un registro chiamato `TSS`, che indicava la pila a disposizione del _job_.
> Per identificare la _pila sistema_ si accedeva prima ad un'altro registro, `TR` (_Task Register_), che indicava quale segmento era associato a quel _job_.
>
> *Fonte: [Protezione.md](./Protezione.md#22-passaggi-tra-contesti)*

**Cosa viene salvato in pila:**
> 7. Salva in pila `5 long word`. In ordine:
> - [0] `SS`: `1 long word` non significativa (rimasuglio della segmentazione, ...)
> - [1] `SRSP`: pila salvata al passo 5. Nel caso di cambio pila è quella `utente`, altrimenti punta alla pila `sistema` stessa
> - [2] `RFLAGS`: registro dei flag
> - [3] `CS`: vecchio valore del `CS` da ripristinare successivamente
> - [4] `RIP`: indirizzo della prima istruzione da eseguire all'uscita del gate.
>
> *Fonte: [Protezione.md](./Protezione.md#22-passaggi-tra-contesti)*

**Esempio pratico nella creazione di processi:**
Nel sistema studiato, la pila sistema viene preparata durante la creazione del processo:

> ```cpp
> pl[-6] = int_cast<natq>(f);		      // RIP (codice sistema)
> pl[-5] = SEL_CODICE_SISTEMA;          // CS (codice sistema)
> pl[-4] = BIT_IF;  	        	      // RFLAGS (abilitiamo le interruzioni)
> pl[-3] = fin_sis_p - sizeof(natq);    // RSP (primo elemento della pila)
> pl[-2] = 0;			                  // SS
> pl[-1] = 0;			                  // ind. rit.
> ```
> *Fonte: [Memoria Virtuale nel Nucleo.md](./Memoria%20Virtuale%20nel%20Nucleo.md)*

**Protezione e sicurezza:**
> Le interruzioni di protezione sono progetatte per poter **solamente _mantenere o alzare_** il _livello di privilegio_.
>
> In particolare, è bene che l'utente non possa modificare il valore salvato di `CS`.
>
> *Fonte: [Protezione.md](./Protezione.md#22-passaggi-tra-contesti)*

**Configurazione della IDT:**
> La `IDT` viene inizializzata tramite il programma di _bootstrap_, in particolare utilizzando l'istruzione `LIDTR` che carica l'indirizzo della `IDT` nel registro `IDTR` che il processore utilizza per accedere ala tabella e allocando `IDT` nella memoria `M1`.
> Per non permettere la modifica di `IDT` da parte dell'utente l'istruzione `LIDTR` è anch'essa **vietata** nel contesto _utente_.
>
> *Fonte: [Protezione.md](./Protezione.md#22-passaggi-tra-contesti)*

In sintesi, i gate della IDT sono meccanismi sofisticati che garantiscono transizioni sicure tra contesti, mentre il nuovo `%rsp` proveniva dal TSS (Task State Segment) che contiene la pila sistema dedicata a ciascun processo, assicurando che le informazioni critiche siano protette dalla corruzione da parte del codice utente. 
Con l'introduzione della paginazione, la base della pila sistema si trova per ogni processo all'indirizzo virtuale `fin_sis_p`, e di conseguenza il nuovo valore di `%rsp` dopo il cambio pila sarà `fin_sis_p - 5 * sizeof(natq)`.

---

### Domanda 3.6
**Domanda:** Cosa sono le interruzioni esterne? A che serve la `apic_send_EOI()`?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 3.7
**Domanda:** Descriva l'annidamento delle interruzioni con l'utilizzo dei due registri ISR e IRR. Cosa comporta programmare con le interruzioni attive?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 3.8
**Domanda:** Quando si accodano le richieste di interruzione su IRR? Perché quando si attraversa il gate viene salvato il registro dei flag?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 3.9
**Domanda:** Come gestiamo le periferiche che agiscono sullo stesso piedino dell'APIC? Quanti piedini ha l'APIC?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 3.10
**Domanda:** Chi configura i registri dell'APIC e la IDT? Chi stabilisce le classi di priorità nelle interruzioni e come si riconoscono?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 3.11
**Domanda:** Spieghi la precedenza su più interruzioni contemporanee. Perché priorità > e non >= per confrontare le richieste di interruzione?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 3.12
**Domanda:** Qual è la differenza tra interrupt su fronte e su livello? È possibile che si perdano interruzioni?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 3.13
**Domanda:** Quando si traduce una funzione in C++ sono ripristinati tutti i registri? Quali sono le istruzioni che ci permettono di usare le interruzioni?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 3.14
**Domanda:** Cosa sono le interruzioni e a cosa servono nel contesto dell'architettura del sistema?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 3.15
**Domanda:** Come si gestisce il problema del Cavallo di Troia nel contesto delle interruzioni e del sistema di protezione?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 3.16
**Domanda:** Perché la gestione con i driver è sconveniente e come si evolve la situazione nel sistema studiato?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 3.17
**Domanda:** Cosa è la preemption e come viene gestita nel sistema multiprogrammato?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 3.18
**Domanda:** Cosa fa, dove e come si salta dopo `carica_stato`? Descriva il meccanismo di cambio di contesto.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 3.19
**Domanda:** Con il timer c'è la possibilità di perdere un'interruzione? Se sì, quando non viene vista?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---
<div class="stop"></div>

---

## 4. Eccezioni

### Domanda 4.1 (answered)
**Domanda:** Qual è la differenza fondamentale tra interruzioni ed eccezioni in termini di quando possono essere sollevate durante l'esecuzione di un'istruzione?

**Risposta:**
La differenza fondamentale tra interruzioni ed eccezioni riguarda il **timing** del loro sollevamento rispetto al ciclo di esecuzione delle istruzioni.

**Interruzioni:**
> Quello che possiamo fare per supportare gli eventi di questa interfaccia è collegare fisicamente il bit della stampante alla **CPU** e aggiungere una $\mu$-istruzione che controlla il bit al termine di ogni istruzione.
>
> *Fonte: [Interruzioni.md](./Interruzioni.md#2-interruzioni)*

Le interruzioni vengono **controllate e accettate solo tra un'istruzione e la successiva**. Il processore verifica la presenza di richieste di interruzione alla fine di ogni istruzione completata, quando il processore si trova in uno stato consistente.

**Caratteristiche delle interruzioni:**
- **Timing**: Solo tra istruzioni complete
- **Asincronia**: Generate da eventi esterni (tastiera, timer, dispositivi I/O)
- **Prevedibilità**: Il processore è sempre in uno stato consistente quando vengono gestite
- **Controllo**: Possono essere mascherate tramite il flag `IF`

**Eccezioni:**
> Mentre le interruzioni possono accedere solo tra un'istruzione e la successiva, le eccezioni possono essere sollevate **in un momento qualunque di un'istruzione** (lettura, decodifica, esecuzione).
>
> *Fonte: [Eccezioni.md](./Eccezioni.md#22-gestione-eccezioni)*

Le eccezioni possono essere sollevate **durante qualsiasi fase dell'esecuzione di un'istruzione**:
- Durante la **fetch** dell'istruzione
- Durante la **decodifica**
- Durante l'**esecuzione** vera e propria

**Classificazione delle eccezioni per timing:**
Dal file [`Eccezioni.md`](./Eccezioni.md#22-gestione-eccezioni):

| Tipo    | Quando viene generata                             | Indirizzo salvato                             | Gestione                                                    |
| ------- | ------------------------------------------------- | --------------------------------------------- | ----------------------------------------------------------- |
| `Fault` | Durante l'esecuzione di un'istruzione             | Indirizzo dell'istruzione che stava eseguendo | Permette la ri-esecuzione dell'istruzione dopo la correzione |
| `Trap`  | Tra l'esecuzione di un'istruzione e la successiva | Indirizzo dell'istruzione successiva          | Comportamento simile alle interruzioni                      |
| `Abort` | In qualsiasi momento                              | -                                             | Errori gravi, spesso irreversibili                          |

**Implicazioni pratiche:**
1. **State saving**: Le eccezioni richiedono meccanismi più complessi per salvare lo stato del processore, dato che possono interrompere un'istruzione a metà
2. **Recovery**: I `Fault` permettono di correggere il problema e riprovare l'istruzione che ha causato l'eccezione
3. **Sincronismo**: Le eccezioni sono sempre sincrone rispetto al flusso di istruzioni, mentre le interruzioni sono asincrone

**Esempio pratico:**
- **Interruzione**: Timer che scatta ogni 50ms, controllato solo alla fine di ogni istruzione
- **Eccezione Fault**: Page fault durante l'accesso a memoria di un'istruzione `LOAD` - l'eccezione viene sollevata durante l'esecuzione dell'istruzione
- **Eccezione Trap**: Breakpoint `int3` - viene sollevata come se fosse tra due istruzioni

Questa distinzione è fondamentale per capire come il processore gestisce gli eventi e mantiene la coerenza del sistema.

---

### Domanda 4.2
**Domanda:** Come funziona l'eccezione di debug `int3` e come viene utilizzata dai debugger per implementare i breakpoint?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 4.3
**Domanda:** Eccezioni: cosa sono e a che servono nel contesto dell'architettura del processore?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 4.4
**Domanda:** Che fa la CPU quando rileva un'eccezione? Come fa la CPU a capire dove saltare?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 4.5
**Domanda:** Descriva il meccanismo dei breakpoint e come vengono implementati a livello hardware e software.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 4.6
**Domanda:** Cosa succede se ho un page fault su una istruzione LOAD? Come viene gestita questa situazione?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---
<div class="stop"></div>

---

## 5. Protezione

### Domanda 5.1
**Domanda:** Perché è necessaria la protezione nei sistemi operativi? Come si distinguono i contesti utente e sistema?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 5.2 (answered)
**Domanda:** Come funzionano i livelli di privilegio nei processori Intel? Quali operazioni sono vietate a livello utente?

**Risposta:**
I livelli di privilegio nei processori Intel x86 sono un meccanismo hardware fondamentale per implementare la **protezione** e garantire la sicurezza del sistema.

> Nel nostro sistema utilizziamo solo due livelli di privilegio:
> - **LIV_SISTEMA**: livello sistema, il più privilegiato
> - **LIV_UTENTE**: livello utente, il meno privilegiato
> 
> *Fonte: [Protezione.md](./Protezione.md)*

Il livello di privilegio corrente è memorizzato nel registro **CS** (Code Selector) e determina quale contesto di esecuzione è attivo.

Il processore distingue tra due contesti principali:

1. **Contesto Sistema**:
   - Ha accesso completo all'hardware
   - Può eseguire tutte le istruzioni privilegiate
   - Può accedere a tutte le aree di memoria

2. **Contesto Utente**:
   - Accesso limitato alle risorse hardware
   - Molte istruzioni sono vietate
   - Accesso limitato alla memoria

> L'idea generale di questo sistema è la seguente:
> 1. All'accensione, tramite il bootstrap, si inizializza il processore a livello `sistema`
> 2. Quando viene inizializzato un job si passa a livello `utente`
> 3. Quando viene generata un'interruzione esterna, si torna al livello `sistema`
> 4. Gestita l'interruzione esterna, si torna al job nel livello `utente`
> 
> *Fonte: [Protezione.md](./Protezione.md)*

Le principali **operazioni vietate** quando il processore opera in contesto utente sono:

- **`IN`** e **`OUT`**: per l'accesso diretto alle porte di I/O
- Queste istruzioni sono controllate dal bit **IOPL** nel registro RFLAGS

> Andremo quindi a **vietare le istruzioni di `IN`, `OUT`, `CLI`, `STI` per il contesto `utente`**, permettendole solamente quando ci si trova nel contesto `sistema`.
> 
> *Fonte: [Protezione.md](./Protezione.md)*

**Controllo delle Interruzioni**
- **`CLI`** (Clear Interrupt Flag): disabilita le interruzioni
- **`STI`** (Set Interrupt Flag): abilita le interruzioni

> Nei processori Intel vi è un'associazione tra `IN` e `OUT` ai comandi `CLI` e `STI`. Se ponessimo il `LIV_UTENTE`, forniremmo l'accesso all'`utente` anche a queste istruzioni, cosa che abbiamo già visto non va fatta.
> 
> *Fonte: [IO.md](./IO.md)*

- **`LIDTR`** (Load Interrupt Descriptor Table Register): carica l'indirizzo della IDT
- **`LGDT`** (Load Global Descriptor Table): carica la GDT
- **`MOV`** verso registri di controllo (CR0, CR2, CR3, CR4)

> Per non permettere la modifica di `IDT` da parte dell'utente l'istruzione `LIDTR` è anch'essa **vietata** nel contesto utente.
> 
> *Fonte: [Protezione.md](./Protezione.md)*

I processi utente non possono accedere direttamente alle aree di memoria riservate al sistema:

> Entrambi i registri sono scrivibili **solo da livello `sistema`**.
> 
> *Fonte: [Paginazione.md](./Paginazione.md)*



Il cambio di livello di privilegio può avvenire solo in modi controllati:

> Il livello di privilegio può essere cambiato solo in due modi:
> 
> | Operazione         | Livello di privilegio    |
> | ------------------ | ------------------------ |
> | gate della `IDT`   | `utente` → `sistema`     |
> | Istruzione `IRETQ` | `sistema` → `utente`     |
> 
> *Fonte: [Protezione.md](./Protezione.md)*

Il passaggio da utente a sistema avviene attraverso i **gate della IDT** tramite:
- **Eccezioni** (es. page fault, protezione)
- **Interruzioni** hardware
- **Chiamate di sistema** (`INT` instruction)

IL passaggio da sistema a utente avviene esclusivamente tramite l'istruzione **`IRETQ`** alla fine delle routine di sistema.

Quando il processore incontra un'istruzione privilegiata in contesto utente, genera un'**eccezione di protezione** (tipo 13):

> Il sistema sul quale lavoriamo è progettato affinché qualsiasi eccezione venga sollevata in modalità utente, restituisce il controllo al modulo sistema, il quale **termina forzatamente il processo** e invia alcuni messaggi sul log.
> 
> *Fonte: [Sistemi Multiprocesso e Processi.md](./Sistemi%20Multiprocesso%20e%20Processi.md)*

Per permettere ai processi utente di accedere ai servizi del sistema operativo in modo controllato, vengono utilizzate le **primitive di sistema**:

> Permetteremo all'utente di utilizzare una determinata eccezione (non modificabile nella memoria), salvando in un registro quale routine si vuole chiamare.
> La Intel ha adottato un sistema diverso, introducendo un nuovo operando assembler `INT $tipo` che fa da gate per chiamare la routine (primitiva di sistema) e passare in modalità `sistema`.
> 
> *Fonte: [Protezione.md](./Protezione.md)*

Questo meccanismo garantisce che:
1. I processi utente non possano interferire con il sistema
2. L'accesso alle risorse hardware sia mediato dal kernel
3. La stabilità e sicurezza del sistema siano preservate

I livelli di privilegio rappresentano quindi una **barriera hardware fondamentale** per l'implementazione della sicurezza nei sistemi operativi moderni.

---

### Domanda 5.3
**Domanda:** Cosa sono M1 e M2? Come viene controllato l'accesso alla memoria per livello di privilegio?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 5.4
**Domanda:** Come funzionano i gate della IDT? Spiega i campi P, I/T, L, DPL.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 5.5
**Domanda:** Descrivi il processo di attraversamento di un gate della IDT. Cosa viene salvato in pila?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 5.6
**Domanda:** Perché è necessario il cambio di pila negli attraversamenti di gate? Come funziona?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 5.7
**Domanda:** Come funziona l'istruzione IRETQ? Quali controlli di sicurezza effettua?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 5.8
**Domanda:** Perché si è resa necessaria l'introduzione della protezione nei sistemi di calcolo? Faccia riferimento all'evoluzione dai sistemi batch ai sistemi multiprogrammati.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 5.9
**Domanda:** Quali problemi sorgerebbero se due job diversi potessero accedere contemporaneamente alle stesse periferiche senza un sistema di protezione?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---
<div class="stop"></div>

---

## 6. Paginazione e Memoria Virtuale

### Domanda 6.1
**Domanda:** Spiega il concetto di memoria virtuale e paginazione. Quali sono i vantaggi della suddivisione della memoria in pagine e frame?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.2
**Domanda:** Qual è la differenza tra indirizzo virtuale e indirizzo fisico? Come avviene la traduzione?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.3 (answered)
**Domanda:** Cosa sono i registri LINF e LSUP? Quali problemi presentano nella gestione della memoria?

**Risposta:**
I registri LINF e LSUP sono una soluzione hardware per implementare la protezione della memoria nei sistemi multi-processo, precedente alla paginazione moderna.

**Funzione dei registri:**
> Per vietare all'`utente` l'accesso alle porzioni di `M2` di processi diversi, si inseriscono nella **CPU** _due registri_, `LINF` e `LSUP`, che hanno come compito quello **di contenere gli indirizzi dell'inizio e della fine della porzione di memoria virtuale del processo in esecuzione**.
> Entrambi i registri sono scrivibili _**solo da livello `sistema`**_.
>
> *Fonte: [Paginazione.md](./Paginazione.md#21-registri-limite-inferiore-e-superiore)*

**Meccanismo di protezione:**
> Quando la **CPU** lavora in modalità `utente`, deve controllare che gli accessi siano in indirizzi **_compresi_** nell'intervallo $\Bigl[$`LINF`, `LSUP`$\Bigr)$.
> In caso di accessi _out-of-bound_ si genererà invece un'eccezione di protezione `13`.

**Gestione durante il cambio processo:**
> Per permettere questa configurazione `LINF` non contiene più il primo indirizzo di `M2`, ma bensì quello della **prima locazione appartenente al processo in esecuzione**.
> Entrambi i registri devono quindi avere una posizione nel vettore `contesto` dei descrittori di processo, ovvero `I_LINF` e `I_LSUP`:
> - <u>Ogni volta</u> che un processo viene caricato dallo _swap_ il `sistema`, riferendosi alla parte di `M2` da lui occupata, **deve inizializzarne i campi**:
>   - `contesto[I_LINF]` con **l'indirizzo iniziale**
>   - `contesto[I_LSUP]` con **l'indirizzo finale**

**Traduzione degli indirizzi:**
> Da adesso in poi, la **CPU** interpreta ogni indirizzo `x` come `LINF + x`.
> In questo modo ogni _indirizzo "assoluto"_ di un processo, adesso indica semplicemente l'_offset_ da `LINF` di quel processo.

**Problemi principali:**

**1. Problema di rilocazione del codice:**
> Il primo risiede nel capire **dove salvare la sezione `.text` di ogni processo**. Infatti, a differenza della memoria unica, dove la sezione `.text` aveva un indirizzo costante dove essere salvata (`LINF`), nel caso di memorie multiple il _collegatore_, si troverà indirizzi di partenza variabili a seconda dello stato del sistema.

Le soluzioni includono:
- Compilazione indipendente dalla posizione (limitata a 32bit/2GB)
- Caricatore rilocante che modifica il programma all'avvio

**2. Problema degli indirizzi assoluti:**
> Un secondo problema risiede nel fatto che i processi potrebbero utilizzare **indirizzi assoluti** per salvare oggetti in memoria.

> Ipotizziamo di avere un processo `P1` che salva un indirizzo assoluto nella sua partizione. Questo processo viene poi **rimosso** e rilocato in un'altra, diversa dalla prima. A questo punto l'indirizzo assoluto che era utilizzato non sarà più disponibile, in quanto si riferisce ad una partizione adesso _out-of-bound_.

**Vincolo forte:**
> _Se un processo è locato in una determinata partizione della memoria, nel caso di scarica e carica, dovrà **sempre** essere rilocato nello stessa posizione._

**3. Frammentazione esterna:**
> Permane comunque il problema della _frammentazione esterna_.

**4. Memoria condivisa limitata:**
> Il terzo problema risiede sulla mancanza di una memoria condivisa, possibile con questo _hardware_, solamente tra processi in partizioni adiacenti.

**Superamento:**
Questi problemi hanno portato allo sviluppo della **paginazione**, che risolve la frammentazione esterna e permette maggiore flessibilità nella gestione della memoria virtuale, eliminando completamente la necessità dei registri LINF e LSUP.

---

### Domanda 6.4
**Domanda:** Qual è il problema della frammentazione esterna e come la paginazione lo risolve?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.5
**Domanda:** Perché è necessario che gli indirizzi Intel x86-64 siano normalizzati? Cosa significa "buco" nella memoria virtuale?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.6
**Domanda:** Spiega la struttura del Trie-MMU. Come funziona il table-walk nella traduzione degli indirizzi?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.7
**Domanda:** Cosa sono le tabelle di livello nel Trie-MMU? Come sono organizzate e indicizzate?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.8
**Domanda:** Qual è la differenza tra descrittori di pagina virtuale e descrittori di tabella?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.9
**Domanda:** Cosa sono le traduzioni identità e perché sono necessarie nel kernel?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.10
**Domanda:** Spiega il funzionamento del TLB (Translation Lookaside Buffer). Perché è necessario per le prestazioni?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.11
**Domanda:** Come viene gestito il bit D (dirty) nel TLB? Qual è il problema e la soluzione?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.12
**Domanda:** Cosa sono le regioni e sottoregioni nella paginazione? Come si calcola la dimensione di una regione di livello i?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.13
**Domanda:** Descrivi le funzioni map() e unmap() per la gestione delle traduzioni. Come funzionano i parametri template?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.14
**Domanda:** Come funziona l'iteratore tab_iter? Qual è la differenza tra visite anticipate e posticipate?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.15
**Domanda:** Spiega i bit di controllo nelle entrate delle tabelle: P, R/W, U/S, PCD, PWT, A, D.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.16
**Domanda:** Come vengono gestite le pagine di grandi dimensioni (2MB, 1GB)? Cosa cambia nel TLB?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.17
**Domanda:** Qual è la differenza tra it.next() e it.down() nell'iteratore tab_iter?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.18
**Domanda:** Come funzionano le espressioni lambda nelle funzioni map() e unmap()? Fornisci un esempio pratico.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.19
**Domanda:** Quali sono i vantaggi che si vogliono preservare nell'implementazione della memoria virtuale? Perché lo swap dell'intera M2 è inefficiente?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.20
**Domanda:** Come è organizzata la memoria virtuale di un processo nel sistema studiato? Descriva la divisione tra sezioni sistema e utente, condivise e private.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.21
**Domanda:** A che serve la Paginazione nel sistema di memoria virtuale?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.22
**Domanda:** Cos'è e com'è implementata la finestra sulla memoria fisica?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.23
**Domanda:** Come è fatto l'albero di traduzione? Descriva i descrittori di tabelle.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.24
**Domanda:** Come si comporta il sistema con il bit D dell'albero di traduzione? Quando va invalidato?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.25
**Domanda:** Descriva il ciclo nelle tabelle di livello 4 e 3 della paginazione.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.26
**Domanda:** Cosa è il descrittore di frame e come viene utilizzato nella gestione della memoria?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.27
**Domanda:** Come vengono gestite le istruzioni LOAD e STORE nel contesto della memoria virtuale?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 6.28
**Domanda:** Descriva il meccanismo del TLB (Translation Lookaside Buffer) e la sua importanza nelle prestazioni.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---
<div class="stop"></div>

---

## 7. Sistemi Multiprocesso e Processi

### Domanda 7.1
**Domanda:** Cosa si intende per processo in un sistema multiprocesso? Quali sono le differenze tra programma e processo?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 7.2
**Domanda:** Cosa comprende il contesto di un processo? Come viene gestito durante i cambi di processo?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 7.3
**Domanda:** Qual è il ruolo del kernel in un sistema multiprocesso? Come riacquisisce il controllo?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 7.4
**Domanda:** Descrivi gli stati di esecuzione di un processo: pronto, esecuzione, bloccato, terminazione.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 7.5
**Domanda:** Come funziona la schedulazione a priorità fissa? Quando è necessaria la schedulazione?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 7.6
**Domanda:** Cosa significa preemption? Quando è necessaria nel nostro sistema?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 7.7
**Domanda:** Come avviene la transizione tra processi tramite i gate della IDT?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 7.8
**Domanda:** Spiega la struttura del descrittore di processo (des_proc). Cosa contiene ogni campo?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 7.9
**Domanda:** Come viene creato un nuovo processo tramite activate_p()? Cosa viene inizializzato?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 7.10
**Domanda:** Cosa contiene la pila sistema di un processo? Come vengono impostati RIP, CS, RFLAGS?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 7.11
**Domanda:** Qual è il ruolo del processo dummy? Perché è necessario?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 7.12
**Domanda:** Come vengono salvati e ripristinati i registri durante il cambio di contesto?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 7.13
**Domanda:** Cosa fanno le funzioni salva_stato e carica_stato? Come si relazionano con la variabile esecuzione?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 7.14
**Domanda:** Descrivi l'organizzazione dei moduli sistema, io e utente. Come interagiscono tra loro?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---
<div class="stop"></div>

---

## 8. Realizzazione delle Primitive

### Domanda 8.1
**Domanda:** Qual è la differenza tra programma e processo? Faccia degli esempi concreti per chiarire questa distinzione fondamentale.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 8.2
**Domanda:** Cos'è il contesto di un processo e come viene gestito il cambio di contesto in un sistema multiprogrammato?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 8.3
**Domanda:** Descriva l'implementazione del cambio contesto. Cosa fa `salva_stato()`?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 8.4
**Domanda:** Come avviene la creazione dei processi nel sistema? Quali sono gli stati di esecuzione dei processi?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 8.5
**Domanda:** A che punto del codice un processo si può dire effettivamente in esecuzione?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 8.6
**Domanda:** Come funziona l'I/O nel sistema multiprogrammato? Quali sono gli accorgimenti da fare per mutex e sync?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 8.7
**Domanda:** Descriva l'avvio del sistema: quali strutture vengono create e come vengono inizializzate?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 8.8
**Domanda:** Come avviene il cambio di processo? Perché `punt_nucleo` punta alla base?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 8.9
**Domanda:** Come si passa il parametro alla `activate_p()`? Chi è che usa `punt_nucleo`?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 8.10
**Domanda:** Perché usiamo una pila sistema diversa per ogni processo?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 8.11
**Domanda:** Come facciamo nel nostro nucleo a creare un modo per far sì che i processi partano e dopo un tot di tempo vadano in fondo alla coda pronti?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 8.12
**Domanda:** E se il processo si sospende su un semaforo? Come viene gestita questa situazione?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 8.13
**Domanda:** Come è organizzata la memoria virtuale di un processo nel sistema studiato?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 8.14
**Domanda:** Spieghi il problema dell'interferenza tra flussi di esecuzione. Faccia un esempio concreto di cosa potrebbe accadere durante l'inserimento di un processo nella coda "pronti".

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 8.15
**Domanda:** Come viene risolto il problema degli stati inconsistenti nelle strutture dati del sistema? Perché la disabilitazione delle interruzioni è cruciale?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---
<div class="stop"></div>

---

## 9. Semafori

### Domanda 9.1
**Domanda:** Definisca i due problemi fondamentali della programmazione concorrente: mutua esclusione e sincronizzazione. Faccia esempi pratici per entrambi.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 9.2
**Domanda:** Come funzionano i semafori di Dijkstra? Spieghi le operazioni di inserimento e prelievo dei gettoni e il comportamento in caso di semaforo vuoto.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 9.3
**Domanda:** Parli in generale dei semafori: a cosa servono, struttura del codice, primitive semaforiche.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 9.4
**Domanda:** Descriva il problema della mutua esclusione e come viene risolto tramite i semafori.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---
<div class="stop"></div>

---

## 10. Delay e Gestione del Tempo

### Domanda 10.1
**Domanda:** Come viene implementata la primitiva `delay(n)` nel sistema? Perché non si decrementa semplicemente un contatore per ogni processo sospeso?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 10.2
**Domanda:** Spieghi l'algoritmo di gestione della lista ordinata dei processi sospesi. Come vengono calcolati i valori relativi invece che assoluti?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---
<div class="stop"></div>

---

## 11. Bus PCI

### Domanda 11.1
**Domanda:** Quali problemi risolve lo standard PCI rispetto al bus ISA? Come viene evitato il problema degli indirizzi sovrapposti?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 11.2
**Domanda:** Cosa sono i tre spazi di indirizzamento definiti dallo standard PCI e qual è il ruolo dello spazio di configurazione?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---
<div class="stop"></div>

---

## 12. I/O e Driver

### Domanda 12.1
**Domanda:** Perché in un sistema protetto un processo non può dialogare direttamente con le periferiche? Come vengono gestite le primitive di I/O?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 12.2
**Domanda:** Qual è la differenza di ruolo tra primitive e driver nelle operazioni di I/O? Come collaborano per gestire la concorrenza?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 12.3
**Domanda:** Descriva l'I/O con primitiva di sistema. Come funziona la primitiva di lettura da interfaccia?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 12.4
**Domanda:** Perché la primitiva di lettura non salva né carica lo stato del processo?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 12.5
**Domanda:** Come funziona il driver e chi lo chiama nel sistema di I/O?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 12.6
**Domanda:** Com'è collegato il modulo I/O con il resto del sistema?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 12.7
**Domanda:** Come funziona la `activate_pe()`? Cosa fa la `wfi()`?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 12.8
**Domanda:** Descriva la primitiva di lettura nel dettaglio e il suo funzionamento.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 12.9
**Domanda:** Quali sono le differenze tra primitiva di sistema e driver, primitiva di I/O e handler?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 12.10
**Domanda:** Come viene gestita la differenza tra Bus Mastering e le primitive di I/O tradizionali?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 12.11
**Domanda:** Descriva il processo di configurazione e inizializzazione del sistema I/O all'avvio.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 12.12
**Domanda:** Come viene gestita la sincronizzazione tra processi e operazioni di I/O?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 12.13
**Domanda:** Quali sono i vantaggi e gli svantaggi dell'approccio con driver separati?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 12.14
**Domanda:** Come viene garantita la protezione nell'accesso alle periferiche tramite il sistema di I/O?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---
<div class="stop"></div>

---

## 13. DMA (Direct Memory Access)

### Domanda 13.1
**Domanda:** Cos'è il DMA e quali vantaggi offre rispetto al controllo di programma e alle interruzioni?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 13.2
**Domanda:** Come funziona il meccanismo HOLD/HOLDA nel DMA? Cos'è il "cycle stealing"?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 13.3
**Domanda:** Quali problemi nascono dall'interazione tra DMA e cache? Come si risolvono nelle politiche write-through e write-back?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 13.4
**Domanda:** Cosa sono lo snooping e lo snarfing nella gestione della cache con DMA?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 13.5
**Domanda:** Come interagisce il DMA con la MMU? Quali problemi sorgono con la memoria virtuale?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 13.6
**Domanda:** Cos'è il PCI Bus Mastering? Come funziona l'arbitraggio tra più dispositivi?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 13.7
**Domanda:** Cosa sono i PRD (Physical Region Descriptors)? Come gestiscono buffer discontigui?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 13.8
**Domanda:** Quali sono i registri del Bus Master IDE Controller e come vengono programmati?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 13.9
**Domanda:** Qual è il problema dei confini di 64KiB nel DMA? Come si risolve?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 13.10
**Domanda:** Come funziona la bufferizzazione nel ponte PCI e quali problemi crea con le interruzioni?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*


---

### Domanda 13.11
**Domanda:** Confronti le tre modalità di trasferimento dati: controllo di programma, interruzioni e DMA. Quali sono vantaggi e svantaggi di ciascuna?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 13.12
**Domanda:** Come funziona il protocollo HOLD/HOLDA per l'arbitraggio dell'accesso alla RAM in modalità DMA? Descriva i passi della comunicazione.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 13.13 (answered)
**Domanda:** Spieghi l'interazione tra DMA e cache. Quali problemi sorgono con le politiche `write-through` e `write-back` e come vengono risolti nei processori Intel e ARM?

**Risposta:**
L'interazione tra DMA e cache presenta sfide significative per la coerenza dei dati, poiché il DMA accede direttamente alla RAM bypassando la cache della CPU.

**Problemi principali:**
> Questi problemi nascono dal fatto che le operazioni del `DMA` potrebbero coinvolgere parti di **RAM** che erano state _**precedentemente copiate in cache**_.
>
> *Fonte: [DMA.md](./DMA.md#21-interazione-con-la-cache)*

**Politica Write-Through:**
Con la politica `write-through`, dal file [`DMA.md`](./DMA.md#211-politica-write-through):

*Soluzione Hardware (Intel):*
> Nei processori _Intel_ la soluzione è risolta in `hardware`. Si fa in modo che il _controllore cache_ **_osservi tutte le possibili sorgenti di scritture in RAM_** attraverso il bus condiviso, processo chiamato di _snooping_.

> Se le linee di controllo identificano un operazione di _scrittura_, il controllore può usare il contenuto delle linee di indirizzo per eseguire una normale ricerca in _cache_, e **nel caso di `hit` invalidare in autonomia la corrispondente `cacheline`**.

*Soluzione Software (ARM):*
> Nei sistemi `ARM` il problema è invece delegato al _software_, tramite istruzioni dedicate che permettono alla **CPU** di interagire direttamente con il _controllore cache_ e invalidarne le `cacheline`. Il _software_ dovrà quindi eseguire tutte le istruzioni specificando l'intervallo `[b, b+n)` (allineato opportunamente alle _cacheline_) **_subito dopo che il trasferimento sia terminato_**.

**Politica Write-Back:**
> In questa politica le scritture della **CPU** vengono mantenute soltanto in _cache_ e effettuate in maniera _sincrona_ in secondi momenti. Questa politica comporta un problema sia nelle operazioni di _uscita_ su `DMA`, poiché il buffer di lettura in **RAM** **potrebbe contenere memoria non aggiornata**.
>
> *Fonte: [DMA.md](./DMA.md#21-interazione-con-la-cache)*

**Esempio pratico - Gestione letture DMA:**
> Per risolvere possiamo utilizzare la tecinca di _snooping_, ma in questo caso il _controllore cache_ **_deve implementare lo snarfing per le cacheline dirty_**.
>
> *Fonte: [DMA.md](./DMA.md#21-interazione-con-la-cache)*

**Differenze principali:**
- **Intel**: Risoluzione hardware automatica tramite snooping
- **ARM**: Risoluzione software con istruzioni dedicate per invalidazione cache
- **Write-through**: Problemi minori, risolti con invalidazione
- **Write-back**: Problemi più complessi, richiedono gestione delle cacheline dirty

---

### Domanda 13.15
**Domanda:** Descriva lo schema del DMA e che problema risolve rispetto alle modalità tradizionali di trasferimento.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 13.16
**Domanda:** Come funziona il DMA con cache Write-Through in modalità hardware e software?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 13.17
**Domanda:** Descriva il DMA con cache Write-Back e trasferimenti di cacheline intere, sia hardware che software.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 13.18
**Domanda:** Come funziona il DMA con cache Write-Back e trasferimenti generici in modalità hardware e software?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 13.19
**Domanda:** Descriva i controlli sugli indirizzi dei buffer nel DMA e il ruolo della funzione `trasforma`.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 13.20
**Domanda:** Descriva il meccanismo di PCI Bus Mastering e l'interazione con le interruzioni. Come viene risolto il problema della bufferizzazione nel ponte PCI?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---
<div class="stop"></div>

---

## 14. Architettura Moderna CPU

### Domanda 14.1 (answered)
**Domanda:** Descriva le dipendenze sui dati e sui nomi nell'esecuzione delle istruzioni. Come vengono gestite?

**Risposta:**
Le dipendenze nell'esecuzione delle istruzioni sono vincoli che impediscono di riordinare liberamente le istruzioni per mantenere la correttezza semantica del programma. Nell'architettura moderna delle CPU sono fondamentali per l'esecuzione fuori ordine.

**Classificazione delle dipendenze:**
> Affinché il risultato finale dei registri sia significativo, dobbiamo rispettare una serie di condizioni chiamate **_Dipendenze_**, che si dividono in tre tipi:
> - **_Dipendenze sui Dati_**
> - **_Dipendenze sui Nomi_**
> - **_Dipendenze sui Controllo_**
> 
> Le **_dipendenze_** sono **proprietà del programma**, _indipendenti dal circuito che esegue il programma_.
>
> *Fonte: [Architettura Moderna CPU Intel.md](./Architettura%20Moderna%20CPU%20Intel.md#33-dipendenze)*

**1. Dipendenze sui Dati (Data Dependencies)**

**Definizione:**
> Un'istruzione `i` **dipende dai dati** di un'altra istruzione `j`, _precedente ad essa_, se `i` utilizza come uno dei registri `src` il registro `dst` di `j`.

**Esempio:**
```x86asm
ADD R1, R2, R3
; ...
SUB R3, R4, R5  ; R3 dipende dal risultato della ADD
```

**Caratteristiche:**
> Le **_Dipendenze sui Dati_** forzano le istruzioni dipendenti a _non poter essere riordinate liberamente_, poiché è necessario che l'istruzione `i` venga eseguita <u>dopo</u> `j`, per avere il contenuto corretto del registro che dovrà utilizzare.

**2. Dipendenze sui Nomi (Name Dependencies)**

Le dipendenze sui nomi si dividono in due categorie:

**A) Antidipendenze (WAR - Write After Read):**
> Un'istruizone `i` si dice _**antidipendente**_ da un'altra istruzione `j`, _successiva ad essa_, se `i` utilizza come `src` lo stesso registro `dst` di `j`.

**Esempio:**
```x86asm
ADD R1, R2, R3    ; Legge R1
; ...
SUB R4, R5, R1    ; Scrive R1 - antidipendenza
```

**B) Dipendenze in uscita (WAW - Write After Write):**
> Un'istruzione `i` si dice **_dipendente in uscita_** rispetto ad un'altra `j`, se entrambe vogliono scrivere nello stesso registro `dst`.

**Esempio:**
```x86asm
ADD R1, R2, R3    ; Scrive R3
; ...
SUB R4, R5, R3    ; Scrive R3 - dipendenza in uscita
```

**Gestione delle dipendenze:**
Dal file [`Architettura Moderna CPU Intel.md`](./Architettura%20Moderna%20CPU%20Intel.md#331-dipendenze-sui-dati):

**1. Gestione dipendenze sui dati:**
> Per risolvere questo tipo di dipendenze, facciamo in modo che l'`emissione` setti il bit `W` del registro `dst` dell'istruzione che sta emettendo.
> 
> La stazione di `emissione`, prima di inviare i dati alla `ALU`, valuterà il bit `W` dei sorgenti, inviandoli **solamente quando `dst->W == 0`**.

**2. Gestione dipendenze sui nomi:**
> Un modo per risolvere le **dipendenze sui nomi** è far andare in **stallo l'`emissione`**. Questa può infatti entrare e uscire liberamente dallo stato di stallo, tramite dei controlli.

**Controlli specifici:**
- **Dipendenze in uscita**: Si controlla il bit `dst->W`, propagando l'istruzione solo se `dst->W == 0`
- **Antidipendenze**: Si valuta il campo `dst->C`, propagando solo se `dst->C == 0`

**3. Rinomina dei registri (Register Renaming):**
> Per quanto riguarda le **dipendenze sui nomi**, esse sono anche chiamate **dipendenze fittizie**, questo perché se andiamo a sovrascrivere il contenuto di un registro è perché adesso lo vogliamo utilizzare per fare altro.
> 
> Possiamo quindi risolverle in questo modo:
> - _Antidipendenze_: è sufficiente cambiare il registro `dst` di `j`.
> - _Dipendenze in uscita_: cerchiamo per ogni scrittura un registro non utilizzato da nessun'altro.

**Implementazione con registri logici e fisici:**
> Un modo per semplificare questo passaggio è inserire, prima degli $n$ registri fisici `Fi`, una tabella contentente $m$ **_registri logici_** `Ri` che punteranno ai registri fisici non in uso.
> 
> In questa nuova architettura, le istruzioni tradotte dalla `decode` faranno riferimento ai **registri logici**.
> 
> L'`emissione` si preoccuperà quindi anche di tradurli in _**registri fisici**_ `Fi` con l'accortezza che:
> Il `dst` di una operazione deve **sempre** essere un registro fisico _attualmente non puntato da nessun altro e non utilizzato dalla `ALU`_ (`W == 0 && Count == 0`).

**Vantaggi del sistema:**
La gestione efficace delle dipendenze permette:
- **Esecuzione fuori ordine**: Le istruzioni possono essere eseguite non appena i loro operandi sono disponibili
- **Esecuzione speculativa**: Le istruzioni possono essere eseguite prima di sapere se dovranno essere effettivamente completate
- **Parallelismo**: Più istruzioni indipendenti possono essere eseguite contemporaneamente

Questo sistema è alla base delle moderne CPU Intel e permette di ottenere prestazioni elevate mantenendo la correttezza semantica dei programmi.

---

### Domanda 14.2
**Domanda:** Spieghi l'esecuzione speculativa e out of order con diagrammi. Come funziona la pipeline?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 14.3
**Domanda:** Descriva l'esecuzione speculativa nel dettaglio e i suoi vantaggi/svantaggi.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 14.4
**Domanda:** Come si risolvono le dipendenze sui nomi? A cosa serve la rinomina dei registri?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 14.5
**Domanda:** Come si risolvono le dipendenze sul controllo nell'architettura moderna?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 14.6
**Domanda:** Cosa è il ROB (Reorder Buffer) e a cosa serve nell'esecuzione out-of-order?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 14.7
**Domanda:** Qual è la differenza tra registri logici e fisici nell'architettura moderna?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 14.8
**Domanda:** Parli delle pipeline nell'architettura moderna e dei loro vantaggi.

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 14.9
**Domanda:** Come vengono gestite le istruzioni LOAD e STORE nell'esecuzione speculativa?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 14.10
**Domanda:** Descriva i problemi di sicurezza legati alla speculazione (Meltdown, Spectre).

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---

### Domanda 14.11
**Domanda:** Come funziona l'interazione tra esecuzione speculativa e cache nelle CPU moderne?

**Risposta:**
*[La risposta verrà aggiunta quando richiesta]*

---
<div class="stop"></div>

---

## Note per lo Studio

- Le risposte verranno aggiunte progressivamente durante le sessioni di studio
- Ogni risposta includerà riferimenti specifici ai file sorgente
- Gli esempi pratici aiuteranno a consolidare i concetti teorici
- Si consiglia di rispondere prima autonomamente e poi confrontare con la risposta ufficiale
